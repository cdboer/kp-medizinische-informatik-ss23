{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - MIMIC-IV Dataset in PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook has been implemented using Python 3.10.11.  \n",
    "The MIMIC-IV v2.2 dataset has been loaded into PostgreSQL server running PostgreSQL 15.2 (Ubuntu 15.2-1.pgdg22.04+1).  \n",
    "We suggest creating a virtual environment for this notebook.  \n",
    "You need to install the following packages to run this notebook:\n",
    "\n",
    "| Package Name | License                                                                                                                 | Documentation                           |\n",
    "|--------------|-------------------------------------------------------------------------------------------------------------------------|-----------------------------------------|\n",
    "| psycopg2     | [![License: LGPL v3](https://img.shields.io/badge/License-LGPL_v3-blue.svg)](https://www.gnu.org/licenses/lgpl-3.0)     | [Docs](https://www.psycopg.org/)        |\n",
    "| pandas       | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://pandas.pydata.org/)      |\n",
    "| numpy        | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://numpy.org/)              |\n",
    "| seaborn      | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://seaborn.pydata.org/)     |\n",
    "| scipy        | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://scipy.org/)              |\n",
    "| tomli        | [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)               | [Docs](https://github.com/hukkin/tomli) |\n",
    "| tqdm         | [![License](https://img.shields.io/pypi/l/tqdm.svg)](https://github.com/tqdm/tqdm/blob/master/LICENCE)                  | [Docs](https://tqdm.github.io/)         |\n",
    "| matplotlib   | [(BSD-compatible, PSF-based)](https://matplotlib.org/stable/users/project/license.html)                                 | [Docs](https://matplotlib.org/)         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Update pip and install requirements.\"\"\"\n",
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Relevant imports for EDA; setup and styling.\"\"\"\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data vizualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# tqdm for progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# default styling for plots\n",
    "plt.style.use(\"ggplot\")  # gnuplot style\n",
    "rcParams[\"figure.figsize\"] = 12, 6  # figure size\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# hls colormap for sns styled pie charts using matplotlib\n",
    "hls = ListedColormap(sns.color_palette(\"hls\").as_hex())\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions for database connection, query execution, dataframe plotting.\"\"\"\n",
    "\n",
    "import tomli as toml\n",
    "import psycopg2 as pg\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def read_config(path: str) -> dict:\n",
    "    \"\"\"Read config file and return config dict.\"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        config = toml.load(f)[\"database\"]\n",
    "    return config\n",
    "\n",
    "\n",
    "def connect_to_db(config: dict) -> Any:\n",
    "    \"\"\"Connect to database and return connection object.\"\"\"\n",
    "    conn = pg.connect(**config)\n",
    "    cur = conn.cursor()\n",
    "    return conn, cur\n",
    "\n",
    "\n",
    "def read_sql(path: str) -> str:\n",
    "    \"\"\"Read SQL file and returns string\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        sql = f.read()\n",
    "    return sql\n",
    "\n",
    "\n",
    "def sql_to_df(path: str, params: dict = None) -> pd.DataFrame:\n",
    "    \"\"\"Read SQL file, execute query and return pandas DataFrame.\n",
    "    \n",
    "    Optionally, pass parameters to query using the params dict.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    conn, cur = connect_to_db(read_config(\"./config.toml\"))\n",
    "    cur.execute(read_sql(path), params)\n",
    "    df = pd.DataFrame(cur.fetchall(), columns=[desc[0] for desc in cur.description])\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_corr_matrix(\n",
    "    df: pd.DataFrame,\n",
    "    method: str = \"pearson\",\n",
    "    title: str=\"\",\n",
    "    figsize=(10, 5),\n",
    "    linewidth=0.3,\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 10},\n",
    "    cmap=\"Spectral_r\",\n",
    "    cbar=True,\n",
    "    ax=None,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ") -> None:\n",
    "    \"\"\"Plot heatmap of correlation matrix.\"\"\"\n",
    "    # set figure size\n",
    "    if ax is None:\n",
    "        plt.subplots(figsize=figsize)\n",
    "    corr = df.corr(method)\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        cbar=cbar,  # show color bar? yes/no\n",
    "        annot=True,  # show numbers in cells? yes/no\n",
    "        square=True,  # square cells? yes/no\n",
    "        linewidths=linewidth,  # linewidth between cells\n",
    "        fmt=fmt,  # precision\n",
    "        annot_kws=annot_kws,  # size of numbers in cells\n",
    "        yticklabels=df.columns,  # y-axis labels\n",
    "        xticklabels=df.columns,  # x-axis labels\n",
    "        cmap=cmap,  # color palette\n",
    "        ax=ax,  # axes object\n",
    "        cbar_kws=cbar_kws,  # shrink color bar\n",
    "    )\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_boxplot_grid(df: pd.DataFrame, target: str) -> None:\n",
    "    \"\"\"Plot boxplots of multiple columns against a single target variable.\"\"\"\n",
    "    # calculate number of rows and columns\n",
    "    n_cols = int(np.ceil(np.sqrt(len(df.columns) - 1)))\n",
    "    n_rows = int(np.ceil((len(df.columns) - 1) / n_cols))\n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_rows, ncols=n_cols, figsize=(n_cols * 6, n_rows * 5)\n",
    "    )\n",
    "    # iterate over columns, rows and create boxplots\n",
    "    for col, ax in zip(df.columns.drop(target), axes.flatten()):\n",
    "        sns.boxplot(x=target, y=col, data=df, ax=ax)\n",
    "        # set title to column name vs. target\n",
    "        ax.set_title(f\"{col} vs. {target}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_corr_matrix_diff(\n",
    "    df_one: pd.DataFrame,\n",
    "    df_two: pd.DataFrame,\n",
    "    method: str = \"pearson\",\n",
    "    figsize=(10, 5),\n",
    "    cmap=\"vlag\",\n",
    "    title=\"\",\n",
    "    ax=None,\n",
    ") -> None:\n",
    "    \"\"\"Plot heatmap of difference of correlation matrices.\"\"\"\n",
    "    # calculate difference of correlation matrices\n",
    "    corr_diff = df_one.corr(method) - df_two.corr(method)\n",
    "    # plot heatmap\n",
    "    plt.subplots(figsize=figsize)\n",
    "    # draw arrows in cells according to correlation difference?\n",
    "    sns.heatmap(\n",
    "        corr_diff,\n",
    "        annot=True,\n",
    "        annot_kws={\"size\": 10},\n",
    "        cbar=True,\n",
    "        cmap=cmap,\n",
    "        fmt=\".2f\",\n",
    "        square=True,\n",
    "        center=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.title(title)\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_pie_chart(df, col=\"race\", title=\"\", ax=None, cmap=hls, explode=.1):\n",
    "    \"\"\"Plot pie chart for a given column in a dataframe.\"\"\"\n",
    "    explode = [explode] * len(df[col].value_counts())\n",
    "    df[col].value_counts().plot.pie(\n",
    "        shadow=True,\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "        title=title,\n",
    "        cmap=cmap,\n",
    "        ax=ax,\n",
    "        labeldistance=1.1,\n",
    "        pctdistance=0.5,\n",
    "        explode=explode,\n",
    "    )\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = None\n",
    "variables_unfiltered = None\n",
    "import threading\n",
    "\n",
    "def getVariables():\n",
    "    global variables\n",
    "    variables = sql_to_df(\"./sql/variables_filtered.sql\", {\"window_size_h\": 8, \"window_stop_size_h\": 2})\n",
    "def getUnfiltered():\n",
    "    global variables_unfiltered\n",
    "    variables_unfiltered = sql_to_df(\"./sql/variables.sql\")\n",
    "\n",
    "x1 = threading.Thread(target=getVariables)\n",
    "x2 = threading.Thread(target=getUnfiltered)\n",
    "x1.start()\n",
    "#x2.start()\n",
    "x1.join()\n",
    "#x2.join()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "#d = defaultdict(int)\n",
    "#columns = variables.columns\n",
    "#for i, row in variables.iterrows():\n",
    "#    counter = 0\n",
    "#    for c in columns:\n",
    "#        x = pd.isnull(row[c])\n",
    "#        if isinstance(x, bool):\n",
    "#            if x:\n",
    "#                counter = counter + 1\n",
    "#        else:\n",
    "#            if x.any():\n",
    "#                counter = counter + 1\n",
    "#    d[counter] += 1#\n",
    "\n",
    "#print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(sorted(d.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = variables.fillna(-1) # this removes all rows currently xD we need to fill those\n",
    "print(set)\n",
    "\n",
    "trainingsset = set.drop([\"sepsis\"], axis=1)\n",
    "labels = set[\"sepsis\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingsset, labels, test_size=0.11, random_state=44, stratify=labels)\n",
    "\n",
    "trainingsset_nan = variables.drop([\"sepsis\"], axis=1)\n",
    "labels_nan = variables[\"sepsis\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_nan, X_test_nan, y_train_nan, y_test_nan = train_test_split(trainingsset_nan, labels_nan, test_size=0.11, random_state=44, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "# import the regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "rdmForest = RandomForestClassifier(random_state = 44) \n",
    "dcsTree = DecisionTreeRegressor(random_state = 44) \n",
    "regressor = LogisticRegression(random_state = 44) \n",
    "gBoost = GradientBoostingClassifier(random_state = 44) \n",
    "xtrTree = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=44, n_jobs=-1)\n",
    "hist = HistGradientBoostingClassifier(random_state=44)\n",
    "gNB = GaussianNB()\n",
    "knc = KNeighborsClassifier()\n",
    "v = VotingClassifier(estimators=[(\"RandomForestClassifier\", rdmForest), (\"GradientBoostingClassifier\", gBoost), (\"ExtraTreesClassifier\", xtrTree), (\"HistGradientBoostingClassifier\", hist)], voting=\"hard\")\n",
    "\n",
    "def forestThread():\n",
    "    # create a regressor object\n",
    "    rdmForest.fit(X_train, y_train)\n",
    "def xtraThread():\n",
    "    xtrTree.fit(X_train, y_train)\n",
    "def dcsTreeThread():\n",
    "    dcsTree.fit(X_train, y_train)\n",
    "def gBoostThread():\n",
    "    gBoost.fit(X_train, y_train)\n",
    "def regressorThread():\n",
    "    regressor.fit(X_train, y_train)\n",
    "def histThread():\n",
    "    hist.fit(X_train_nan, y_train_nan)\n",
    "def gNBThread():\n",
    "    gNB.fit(X_train, y_train)\n",
    "def kncThread():\n",
    "    knc.fit(X_test, y_test)\n",
    "def vThread():\n",
    "    v.fit(X_test, y_test)\n",
    "\n",
    "x1 = threading.Thread(target=forestThread)\n",
    "x2 = threading.Thread(target=dcsTreeThread)\n",
    "x3 = threading.Thread(target=gBoostThread)\n",
    "x4 = threading.Thread(target=regressorThread)\n",
    "x5 = threading.Thread(target=histThread)\n",
    "x6 = threading.Thread(target=gNBThread)\n",
    "x7 = threading.Thread(target=kncThread)\n",
    "x8 = threading.Thread(target=vThread)\n",
    "\n",
    "x1.start()\n",
    "x2.start()\n",
    "x3.start()\n",
    "x4.start()\n",
    "x5.start()\n",
    "x6.start()\n",
    "x7.start()\n",
    "x8.start()\n",
    "\n",
    "x1.join()\n",
    "x2.join()\n",
    "x3.join()\n",
    "x4.join()\n",
    "x5.join()\n",
    "x6.join()\n",
    "x7.join()\n",
    "x8.join()\n",
    "\n",
    "print(\"extra\")\n",
    "xtraThread()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_forest = rdmForest.predict(X_test)\n",
    "y_pred_xtr = xtrTree.predict(X_test)\n",
    "y_pred_dcsTree = dcsTree.predict(X_test)\n",
    "y_pred_gBoost = gBoost.predict(X_test)\n",
    "y_pred_regressor = regressor.predict(X_test)\n",
    "y_pred_hist = hist.predict(X_test_nan)\n",
    "y_pred_gNB = gNB.predict(X_test)\n",
    "y_pred_knc = knc.predict(X_test)\n",
    "y_pred_v = v.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "forest_mcc = matthews_corrcoef(y_test, y_pred_forest)\n",
    "xtr_mcc = matthews_corrcoef(y_test, y_pred_xtr)\n",
    "dcsTree_mcc = matthews_corrcoef(y_test, y_pred_dcsTree)\n",
    "gBoost_mcc = matthews_corrcoef(y_test, y_pred_gBoost)\n",
    "regressor_mcc = matthews_corrcoef(y_test, y_pred_regressor)\n",
    "hist_mcc = matthews_corrcoef(y_test_nan, y_pred_hist)\n",
    "gNB_mcc = matthews_corrcoef(y_test, y_pred_gNB)\n",
    "knc_mcc = matthews_corrcoef(y_test, y_pred_knc)\n",
    "v_mcc = matthews_corrcoef(y_test, y_pred_v)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "forest_roc = roc_auc_score(y_test, y_pred_forest)\n",
    "xtr_roc = roc_auc_score(y_test, y_pred_xtr)\n",
    "dcsTree_roc = roc_auc_score(y_test, y_pred_dcsTree)\n",
    "gBoost_roc = roc_auc_score(y_test, y_pred_gBoost)\n",
    "regressor_roc = roc_auc_score(y_test, y_pred_regressor)\n",
    "hist_roc = roc_auc_score(y_test_nan, y_pred_hist)\n",
    "gNB_roc = roc_auc_score(y_test, y_pred_gNB)\n",
    "knc_roc = roc_auc_score(y_test, y_pred_knc)\n",
    "v_roc = roc_auc_score(y_test, y_pred_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[forest_mcc, forest_roc], [xtr_mcc, xtr_roc], [dcsTree_mcc, dcsTree_roc], [gBoost_mcc, gBoost_roc], [regressor_mcc, regressor_roc], [hist_mcc, hist_roc], [gNB_mcc, gNB_roc], [knc_mcc, knc_roc], [v_mcc, v_roc]]\n",
    "df = pd.DataFrame(data, columns=[\"MCC\", \"ROC\"], index=[\"RandomForestClassifier\", \"ExtraTreesClassifier\", \"DecisionTreeRegressor\", \"GradientBoostingClassifier\", \"LogisticRegression\", \"HistGradientBoostingClassifier\", \"GaussianNB\", \"KNeighborsClassifier\", \"Voting\"])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
