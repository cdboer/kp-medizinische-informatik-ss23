{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - MIMIC-IV Dataset in PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook has been implemented using Python 3.10.11.  \n",
    "The MIMIC-IV v2.2 dataset has been loaded into PostgreSQL server running PostgreSQL 15.2 (Ubuntu 15.2-1.pgdg22.04+1).  \n",
    "We suggest creating a virtual environment for this notebook.  \n",
    "You need to install the following packages to run this notebook:\n",
    "\n",
    "| Package Name | License                                                                                                                 | Documentation                           |\n",
    "|--------------|-------------------------------------------------------------------------------------------------------------------------|-----------------------------------------|\n",
    "| psycopg2     | [![License: LGPL v3](https://img.shields.io/badge/License-LGPL_v3-blue.svg)](https://www.gnu.org/licenses/lgpl-3.0)     | [Docs](https://www.psycopg.org/)        |\n",
    "| pandas       | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://pandas.pydata.org/)      |\n",
    "| numpy        | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://numpy.org/)              |\n",
    "| seaborn      | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://seaborn.pydata.org/)     |\n",
    "| scipy        | [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) | [Docs](https://scipy.org/)              |\n",
    "| tomli        | [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)               | [Docs](https://github.com/hukkin/tomli) |\n",
    "| tqdm         | [![License](https://img.shields.io/pypi/l/tqdm.svg)](https://github.com/tqdm/tqdm/blob/master/LICENCE)                  | [Docs](https://tqdm.github.io/)         |\n",
    "| matplotlib   | [(BSD-compatible, PSF-based)](https://matplotlib.org/stable/users/project/license.html)                                 | [Docs](https://matplotlib.org/)         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (23.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: psycopg2-binary==2.9.6 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.9.6)\n",
      "Requirement already satisfied: tomli==2.0.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: pandas==2.0.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: numpy==1.24.3 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
      "Requirement already satisfied: seaborn==0.12.2 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.12.2)\n",
      "Requirement already satisfied: scipy==1.10.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.10.1)\n",
      "Requirement already satisfied: tqdm==4.65.0 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from pandas==2.0.1->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from pandas==2.0.1->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/neo/git/kp-medizinische-informatik-ss23/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.7.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Update pip and install requirements.\"\"\"\n",
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Relevant imports for EDA; setup and styling.\"\"\"\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data vizualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# tqdm for progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# default styling for plots\n",
    "plt.style.use(\"ggplot\")  # gnuplot style\n",
    "rcParams[\"figure.figsize\"] = 12, 6  # figure size\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# hls colormap for sns styled pie charts using matplotlib\n",
    "hls = ListedColormap(sns.color_palette(\"hls\").as_hex())\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions for database connection, query execution, dataframe plotting.\"\"\"\n",
    "\n",
    "import tomli as toml\n",
    "import psycopg2 as pg\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def read_config(path: str) -> dict:\n",
    "    \"\"\"Read config file and return config dict.\"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        config = toml.load(f)[\"database\"]\n",
    "    return config\n",
    "\n",
    "\n",
    "def connect_to_db(config: dict) -> Any:\n",
    "    \"\"\"Connect to database and return connection object.\"\"\"\n",
    "    conn = pg.connect(**config)\n",
    "    cur = conn.cursor()\n",
    "    return conn, cur\n",
    "\n",
    "\n",
    "def read_sql(path: str) -> str:\n",
    "    \"\"\"Read SQL file and returns string\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        sql = f.read()\n",
    "    return sql\n",
    "\n",
    "\n",
    "def sql_to_df(path: str, params: dict = None) -> pd.DataFrame:\n",
    "    \"\"\"Read SQL file, execute query and return pandas DataFrame.\n",
    "    \n",
    "    Optionally, pass parameters to query using the params dict.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    conn, cur = connect_to_db(read_config(\"./config.toml\"))\n",
    "    cur.execute(read_sql(path), params)\n",
    "    df = pd.DataFrame(cur.fetchall(), columns=[desc[0] for desc in cur.description])\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_corr_matrix(\n",
    "    df: pd.DataFrame,\n",
    "    method: str = \"pearson\",\n",
    "    title: str=\"\",\n",
    "    figsize=(10, 5),\n",
    "    linewidth=0.3,\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 10},\n",
    "    cmap=\"Spectral_r\",\n",
    "    cbar=True,\n",
    "    ax=None,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ") -> None:\n",
    "    \"\"\"Plot heatmap of correlation matrix.\"\"\"\n",
    "    # set figure size\n",
    "    if ax is None:\n",
    "        plt.subplots(figsize=figsize)\n",
    "    corr = df.corr(method)\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        cbar=cbar,  # show color bar? yes/no\n",
    "        annot=True,  # show numbers in cells? yes/no\n",
    "        square=True,  # square cells? yes/no\n",
    "        linewidths=linewidth,  # linewidth between cells\n",
    "        fmt=fmt,  # precision\n",
    "        annot_kws=annot_kws,  # size of numbers in cells\n",
    "        yticklabels=df.columns,  # y-axis labels\n",
    "        xticklabels=df.columns,  # x-axis labels\n",
    "        cmap=cmap,  # color palette\n",
    "        ax=ax,  # axes object\n",
    "        cbar_kws=cbar_kws,  # shrink color bar\n",
    "    )\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_boxplot_grid(df: pd.DataFrame, target: str) -> None:\n",
    "    \"\"\"Plot boxplots of multiple columns against a single target variable.\"\"\"\n",
    "    # calculate number of rows and columns\n",
    "    n_cols = int(np.ceil(np.sqrt(len(df.columns) - 1)))\n",
    "    n_rows = int(np.ceil((len(df.columns) - 1) / n_cols))\n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_rows, ncols=n_cols, figsize=(n_cols * 6, n_rows * 5)\n",
    "    )\n",
    "    # iterate over columns, rows and create boxplots\n",
    "    for col, ax in zip(df.columns.drop(target), axes.flatten()):\n",
    "        sns.boxplot(x=target, y=col, data=df, ax=ax)\n",
    "        # set title to column name vs. target\n",
    "        ax.set_title(f\"{col} vs. {target}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_corr_matrix_diff(\n",
    "    df_one: pd.DataFrame,\n",
    "    df_two: pd.DataFrame,\n",
    "    method: str = \"pearson\",\n",
    "    figsize=(10, 5),\n",
    "    cmap=\"vlag\",\n",
    "    title=\"\",\n",
    "    ax=None,\n",
    ") -> None:\n",
    "    \"\"\"Plot heatmap of difference of correlation matrices.\"\"\"\n",
    "    # calculate difference of correlation matrices\n",
    "    corr_diff = df_one.corr(method) - df_two.corr(method)\n",
    "    # plot heatmap\n",
    "    plt.subplots(figsize=figsize)\n",
    "    # draw arrows in cells according to correlation difference?\n",
    "    sns.heatmap(\n",
    "        corr_diff,\n",
    "        annot=True,\n",
    "        annot_kws={\"size\": 10},\n",
    "        cbar=True,\n",
    "        cmap=cmap,\n",
    "        fmt=\".2f\",\n",
    "        square=True,\n",
    "        center=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.title(title)\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_pie_chart(df, col=\"race\", title=\"\", ax=None, cmap=hls, explode=.1):\n",
    "    \"\"\"Plot pie chart for a given column in a dataframe.\"\"\"\n",
    "    explode = [explode] * len(df[col].value_counts())\n",
    "    df[col].value_counts().plot.pie(\n",
    "        shadow=True,\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "        title=title,\n",
    "        cmap=cmap,\n",
    "        ax=ax,\n",
    "        labeldistance=1.1,\n",
    "        pctdistance=0.5,\n",
    "        explode=explode,\n",
    "    )\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = None\n",
    "variables_unfiltered = None\n",
    "import threading\n",
    "\n",
    "def getVariables():\n",
    "    global variables\n",
    "    variables = sql_to_df(\"./sql/variables_filtered.sql\", {\"window_size_h\": 8, \"window_stop_size_h\": 2})\n",
    "def getUnfiltered():\n",
    "    global variables_unfiltered\n",
    "    variables_unfiltered = sql_to_df(\"./sql/variables.sql\")\n",
    "\n",
    "x1 = threading.Thread(target=getVariables)\n",
    "x2 = threading.Thread(target=getUnfiltered)\n",
    "x1.start()\n",
    "#x2.start()\n",
    "x1.join()\n",
    "#x2.join()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "#d = defaultdict(int)\n",
    "#columns = variables.columns\n",
    "#for i, row in variables.iterrows():\n",
    "#    counter = 0\n",
    "#    for c in columns:\n",
    "#        x = pd.isnull(row[c])\n",
    "#        if isinstance(x, bool):\n",
    "#            if x:\n",
    "#                counter = counter + 1\n",
    "#        else:\n",
    "#            if x.any():\n",
    "#                counter = counter + 1\n",
    "#    d[counter] += 1#\n",
    "\n",
    "#print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(sorted(d.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id  heart_rate_min  heart_rate_max  heart_rate_mean   \n",
      "0        12466550            83.0           128.0       103.285714  \\\n",
      "1        13180007            72.0            90.0        83.333333   \n",
      "2        18421337            -1.0            -1.0        -1.000000   \n",
      "3        12207593            85.0            97.0        91.692308   \n",
      "4        12980335            67.0            80.0        72.166667   \n",
      "...           ...             ...             ...              ...   \n",
      "73176    16180713            57.0            68.0        62.142857   \n",
      "73177    15498623            69.0            72.0        70.714286   \n",
      "73178    11256534            83.0           131.0        97.727273   \n",
      "73179    15403458            98.0           117.0       110.333333   \n",
      "73180    17840864            62.0            66.0        63.750000   \n",
      "\n",
      "       heart_rate_std  sbp_min  sbp_max    sbp_mean    sbp_std  dbp_min  ...   \n",
      "0           18.300403    109.0    155.0  125.500000  16.896745     55.0  ...  \\\n",
      "1            6.801961    118.0    145.0  127.000000   9.899495     47.0  ...   \n",
      "2           -1.000000     -1.0     -1.0   -1.000000  -1.000000     -1.0  ...   \n",
      "3            3.095406     71.0    151.0   92.045455  14.692004     34.0  ...   \n",
      "4            6.242329     99.0    116.0  111.333333   6.250333     52.0  ...   \n",
      "...               ...      ...      ...         ...        ...      ...  ...   \n",
      "73176        4.140393    116.0    148.0  126.000000  12.441865     60.0  ...   \n",
      "73177        1.112697    119.0    140.0  132.333333   8.524475     33.0  ...   \n",
      "73178       13.813695    117.0    140.0  131.636364   7.270113     61.0  ...   \n",
      "73179        6.470446    123.0    140.0  134.000000   9.539392     71.0  ...   \n",
      "73180        1.581139    117.0    144.0  129.375000   9.605616     70.0  ...   \n",
      "\n",
      "       lactatee_std  totalco2_min  totalco2_max  totalco2_mean  totalco2_std   \n",
      "0              -1.0          -1.0          -1.0           -1.0          -1.0  \\\n",
      "1              -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "2              -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "3              -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "4              -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "...             ...           ...           ...            ...           ...   \n",
      "73176          -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "73177          -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "73178          -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "73179          -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "73180          -1.0          -1.0          -1.0           -1.0          -1.0   \n",
      "\n",
      "       ph_min  ph_max  ph_mean  ph_std   stay_id  \n",
      "0        -1.0    -1.0     -1.0    -1.0  30000153  \n",
      "1        -1.0    -1.0     -1.0    -1.0  30000213  \n",
      "2        -1.0    -1.0     -1.0    -1.0  30000484  \n",
      "3        -1.0    -1.0     -1.0    -1.0  30000646  \n",
      "4        -1.0    -1.0     -1.0    -1.0  30001148  \n",
      "...       ...     ...      ...     ...       ...  \n",
      "73176    -1.0    -1.0     -1.0    -1.0  39999301  \n",
      "73177    -1.0    -1.0     -1.0    -1.0  39999384  \n",
      "73178    -1.0    -1.0     -1.0    -1.0  39999552  \n",
      "73179    -1.0    -1.0     -1.0    -1.0  39999562  \n",
      "73180    -1.0    -1.0     -1.0    -1.0  39999810  \n",
      "\n",
      "[73181 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "set = variables.fillna(-1) # this removes all rows currently xD we need to fill those\n",
    "print(set)\n",
    "\n",
    "trainingsset = set.drop([\"sepsis\"], axis=1)\n",
    "labels = set[\"sepsis\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingsset, labels, test_size=0.11, random_state=44, stratify=labels)\n",
    "\n",
    "trainingsset_nan = variables.drop([\"sepsis\"], axis=1)\n",
    "labels_nan = variables[\"sepsis\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_nan, X_test_nan, y_train_nan, y_test_nan = train_test_split(trainingsset_nan, labels_nan, test_size=0.11, random_state=44, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "# import the regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "rdmForest = RandomForestClassifier(random_state = 44) \n",
    "dcsTree = DecisionTreeRegressor(random_state = 44) \n",
    "regressor = LogisticRegression(random_state = 44) \n",
    "gBoost = GradientBoostingClassifier(random_state = 44) \n",
    "xtrTree = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=44, n_jobs=-1)\n",
    "hist = HistGradientBoostingClassifier(random_state=44)\n",
    "gNB = GaussianNB()\n",
    "knc = KNeighborsClassifier()\n",
    "v = VotingClassifier(estimators=[(\"RandomForestClassifier\", rdmForest), (\"GradientBoostingClassifier\", gBoost), (\"ExtraTreesClassifier\", xtrTree), (\"HistGradientBoostingClassifier\", hist)], voting=\"hard\")\n",
    "\n",
    "def forestThread():\n",
    "    # create a regressor object\n",
    "    rdmForest.fit(X_train, y_train)\n",
    "def xtraThread():\n",
    "    xtrTree.fit(X_train, y_train)\n",
    "def dcsTreeThread():\n",
    "    dcsTree.fit(X_train, y_train)\n",
    "def gBoostThread():\n",
    "    gBoost.fit(X_train, y_train)\n",
    "def regressorThread():\n",
    "    regressor.fit(X_train, y_train)\n",
    "def histThread():\n",
    "    hist.fit(X_train_nan, y_train_nan)\n",
    "def gNBThread():\n",
    "    gNB.fit(X_train, y_train)\n",
    "def kncThread():\n",
    "    knc.fit(X_test, y_test)\n",
    "def vThread():\n",
    "    v.fit(X_test, y_test)\n",
    "\n",
    "x1 = threading.Thread(target=forestThread)\n",
    "x2 = threading.Thread(target=dcsTreeThread)\n",
    "x3 = threading.Thread(target=gBoostThread)\n",
    "x4 = threading.Thread(target=regressorThread)\n",
    "x5 = threading.Thread(target=histThread)\n",
    "x6 = threading.Thread(target=gNBThread)\n",
    "x7 = threading.Thread(target=kncThread)\n",
    "x8 = threading.Thread(target=vThread)\n",
    "\n",
    "x1.start()\n",
    "x2.start()\n",
    "x3.start()\n",
    "x4.start()\n",
    "x5.start()\n",
    "x6.start()\n",
    "x7.start()\n",
    "x8.start()\n",
    "\n",
    "x1.join()\n",
    "x2.join()\n",
    "x3.join()\n",
    "x4.join()\n",
    "x5.join()\n",
    "x6.join()\n",
    "x7.join()\n",
    "x8.join()\n",
    "\n",
    "print(\"extra\")\n",
    "xtraThread()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_forest = rdmForest.predict(X_test)\n",
    "y_pred_xtr = xtrTree.predict(X_test)\n",
    "y_pred_dcsTree = dcsTree.predict(X_test)\n",
    "y_pred_gBoost = gBoost.predict(X_test)\n",
    "y_pred_regressor = regressor.predict(X_test)\n",
    "y_pred_hist = hist.predict(X_test_nan)\n",
    "y_pred_gNB = gNB.predict(X_test)\n",
    "y_pred_knc = knc.predict(X_test)\n",
    "y_pred_v = v.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "forest_mcc = matthews_corrcoef(y_test, y_pred_forest)\n",
    "xtr_mcc = matthews_corrcoef(y_test, y_pred_xtr)\n",
    "dcsTree_mcc = matthews_corrcoef(y_test, y_pred_dcsTree)\n",
    "gBoost_mcc = matthews_corrcoef(y_test, y_pred_gBoost)\n",
    "regressor_mcc = matthews_corrcoef(y_test, y_pred_regressor)\n",
    "hist_mcc = matthews_corrcoef(y_test_nan, y_pred_hist)\n",
    "gNB_mcc = matthews_corrcoef(y_test, y_pred_gNB)\n",
    "knc_mcc = matthews_corrcoef(y_test, y_pred_knc)\n",
    "v_mcc = matthews_corrcoef(y_test, y_pred_v)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "forest_roc = roc_auc_score(y_test, y_pred_forest)\n",
    "xtr_roc = roc_auc_score(y_test, y_pred_xtr)\n",
    "dcsTree_roc = roc_auc_score(y_test, y_pred_dcsTree)\n",
    "gBoost_roc = roc_auc_score(y_test, y_pred_gBoost)\n",
    "regressor_roc = roc_auc_score(y_test, y_pred_regressor)\n",
    "hist_roc = roc_auc_score(y_test_nan, y_pred_hist)\n",
    "gNB_roc = roc_auc_score(y_test, y_pred_gNB)\n",
    "knc_roc = roc_auc_score(y_test, y_pred_knc)\n",
    "v_roc = roc_auc_score(y_test, y_pred_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     MCC       ROC\n",
      "RandomForestClassifier          0.731950  0.856081\n",
      "ExtraTreesClassifier            0.726524  0.853721\n",
      "DecisionTreeRegressor           0.629145  0.815064\n",
      "GradientBoostingClassifier      0.770212  0.863860\n",
      "LogisticRegression              0.000000  0.500000\n",
      "HistGradientBoostingClassifier  0.773300  0.866964\n",
      "GaussianNB                      0.594110  0.749104\n",
      "KNeighborsClassifier            0.382642  0.689179\n",
      "Voting                          0.854306  0.915495\n"
     ]
    }
   ],
   "source": [
    "data = [[forest_mcc, forest_roc], [xtr_mcc, xtr_roc], [dcsTree_mcc, dcsTree_roc], [gBoost_mcc, gBoost_roc], [regressor_mcc, regressor_roc], [hist_mcc, hist_roc], [gNB_mcc, gNB_roc], [knc_mcc, knc_roc], [v_mcc, v_roc]]\n",
    "df = pd.DataFrame(data, columns=[\"MCC\", \"ROC\"], index=[\"RandomForestClassifier\", \"ExtraTreesClassifier\", \"DecisionTreeRegressor\", \"GradientBoostingClassifier\", \"LogisticRegression\", \"HistGradientBoostingClassifier\", \"GaussianNB\", \"KNeighborsClassifier\", \"Voting\"])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
